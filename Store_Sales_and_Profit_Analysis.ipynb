{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AHJ6w8ZR-E63oFELuI8cEyCWLTOGJOBx",
      "authorship_tag": "ABX9TyOKsUOAKxt0U4H8e2Godjov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheshmokka/2320040135/blob/main/Store_Sales_and_Profit_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "try:\n",
        "    import statsmodels.api as sm\n",
        "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    HAS_SM = True\n",
        "except:\n",
        "    HAS_SM = False\n"
      ],
      "metadata": {
        "id": "ztG7v--cO2gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uangiLl9QQMr",
        "outputId": "51ef09ca-2349-4c48-8988-5cd18484eebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'  'Sample - Superstore.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATA_PATH, encoding=\"ISO-8859-1\")\n"
      ],
      "metadata": {
        "id": "v2eGksIuQfu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "print(\"\\nSample Data:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV87ZDn2QrKX",
        "outputId": "6c67c57e-f83c-43c5-c4c3-d963c8d3fc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (9994, 21)\n",
            "\n",
            "Columns: ['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit']\n",
            "\n",
            "Sample Data:\n",
            "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
            "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
            "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
            "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
            "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
            "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
            "\n",
            "     Customer Name    Segment        Country             City  ...  \\\n",
            "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
            "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
            "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
            "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
            "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
            "\n",
            "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
            "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
            "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
            "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
            "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
            "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
            "\n",
            "                                        Product Name     Sales  Quantity  \\\n",
            "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
            "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
            "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
            "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
            "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
            "\n",
            "   Discount    Profit  \n",
            "0      0.00   41.9136  \n",
            "1      0.00  219.5820  \n",
            "2      0.00    6.8714  \n",
            "3      0.45 -383.0310  \n",
            "4      0.20    2.5164  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Missing values:\n",
            "Row ID           0\n",
            "Order ID         0\n",
            "Order Date       0\n",
            "Ship Date        0\n",
            "Ship Mode        0\n",
            "Customer ID      0\n",
            "Customer Name    0\n",
            "Segment          0\n",
            "Country          0\n",
            "City             0\n",
            "State            0\n",
            "Postal Code      0\n",
            "Region           0\n",
            "Product ID       0\n",
            "Category         0\n",
            "Sub-Category     0\n",
            "Product Name     0\n",
            "Sales            0\n",
            "Quantity         0\n",
            "Discount         0\n",
            "Profit           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data = df.copy()\n",
        "\n",
        "data.columns = [c.strip() for c in data.columns]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "col_alias = {\n",
        "    \"OrderDate\": \"Order Date\",\n",
        "    \"Order_Date\": \"Order Date\",\n",
        "    \"OrderID\": \"Order ID\",\n",
        "    \"Order_Id\": \"Order ID\",\n",
        "    \"CustomerID\": \"Customer ID\",\n",
        "    \"Customer_Id\": \"Customer ID\",\n",
        "    \"SubCategory\": \"Sub-Category\",\n",
        "    \"ProductName\": \"Product Name\",\n",
        "    \"ProductID\": \"Product ID\",\n",
        "    \"UnitPrice\": \"Unit Price\"\n",
        "}\n",
        "for k,v in col_alias.items():\n",
        "    if k in data.columns and v not in data.columns:\n",
        "        data.rename(columns={k:v}, inplace=True)"
      ],
      "metadata": {
        "id": "Lwhq2XdUQzbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Type fixes & derived fields\n",
        "\n",
        "if DATE_COL not in data.columns:\n",
        "    raise SystemExit(f\"Expected date column '{DATE_COL}' not found. Please rename in script.\")\n",
        "data[DATE_COL] = pd.to_datetime(data[DATE_COL], errors=\"coerce\")\n",
        "data = data.dropna(subset=[DATE_COL])\n",
        "\n",
        "\n",
        "for numcol in [\"Quantity\", \"Sales\", \"Discount\", \"Profit\", \"Cost\", \"Unit Price\"]:\n",
        "    if numcol in data.columns:\n",
        "        data[numcol] = pd.to_numeric(data[numcol], errors=\"coerce\")\n",
        "\n",
        "if \"Quantity\" not in data.columns:\n",
        "    data[\"Quantity\"] = 1\n",
        "if \"Sales\" not in data.columns:\n",
        "    raise SystemExit(\"Need 'Sales' column in the dataset.\")\n",
        "if \"Profit\" not in data.columns:\n",
        "\n",
        "    data[\"Profit\"] = data[\"Sales\"] * (1 - data.get(\"Discount\", pd.Series(0,index=data.index))) * 0.2\n",
        "\n",
        "if \"Unit Price\" not in data.columns:\n",
        "    data[\"Unit Price\"] = data[\"Sales\"] / data[\"Quantity\"].replace(0, np.nan)\n",
        "\n",
        "data[\"Profit Margin %\"] = np.where(\n",
        "    data[\"Sales\"] > 0, (data[\"Profit\"] / data[\"Sales\"]) * 100, np.nan\n",
        ")\n",
        "\n",
        "# Date parts\n",
        "data[\"Year\"] = data[DATE_COL].dt.year\n",
        "data[\"Month\"] = data[DATE_COL].dt.month\n",
        "data[\"Month Name\"] = data[DATE_COL].dt.strftime(\"%b\")\n",
        "data[\"Quarter\"] = data[DATE_COL].dt.to_period(\"Q\").astype(str)\n",
        "data[\"Week\"] = data[DATE_COL].dt.isocalendar().week\n",
        "data[\"Weekday\"] = data[DATE_COL].dt.day_name()"
      ],
      "metadata": {
        "id": "AKrZpFBqQ4Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Global KPIs\n",
        "# -------------------------\n",
        "orders = data[ID_COL].nunique() if ID_COL in data.columns else len(data)\n",
        "customers = data[CUST_COL].nunique() if CUST_COL in data.columns else None\n",
        "total_sales = data[\"Sales\"].sum()\n",
        "total_profit = data[\"Profit\"].sum()\n",
        "avg_order_value = data.groupby(ID_COL)[\"Sales\"].sum().mean() if ID_COL in data.columns else np.nan\n",
        "items_per_order = (data.groupby(ID_COL)[\"Quantity\"].sum().mean()\n",
        "                   if ID_COL in data.columns else np.nan)\n",
        "overall_margin = (total_profit / total_sales * 100) if total_sales else np.nan\n",
        "\n",
        "summary = {\n",
        "    \"Orders\": orders,\n",
        "    \"Customers\": customers,\n",
        "    \"Total Sales\": round(total_sales, 2),\n",
        "    \"Total Profit\": round(total_profit, 2),\n",
        "    \"Overall Margin %\": round(overall_margin, 2),\n",
        "    \"Avg Order Value\": round(avg_order_value, 2) if not np.isnan(avg_order_value) else None,\n",
        "    \"Items/Order\": round(items_per_order, 2) if not np.isnan(items_per_order) else None\n",
        "}\n",
        "pd.Series(summary).to_csv(OUTPUT_DIR / \"kpi_summary.csv\")\n",
        "\n",
        "print(\"== KPI SUMMARY ==\")\n",
        "for k,v in summary.items():\n",
        "    print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tc6a94sRA3r",
        "outputId": "c8150d6c-1f5c-4ebb-ed52-545b311f7786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== KPI SUMMARY ==\n",
            "Orders: 5009\n",
            "Customers: 793\n",
            "Total Sales: 2297200.86\n",
            "Total Profit: 286397.02\n",
            "Overall Margin %: 12.47\n",
            "Avg Order Value: 458.61\n",
            "Items/Order: 7.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Aggregations & Exports\n",
        "# -------------------------\n",
        "def topn(group_cols, metric=\"Sales\", n=10):\n",
        "    g = data.groupby(group_cols, dropna=False, as_index=False)[[\"Sales\",\"Profit\"]].sum()\n",
        "    g[\"Profit Margin %\"] = np.where(g[\"Sales\"]>0, g[\"Profit\"]/g[\"Sales\"]*100, np.nan)\n",
        "    g = g.sort_values(metric, ascending=False).head(n)\n",
        "    return g\n",
        "\n",
        "if \"Product Name\" in data.columns:\n",
        "    top_products = topn([\"Product Name\"], \"Sales\", 20)\n",
        "    top_products.to_csv(OUTPUT_DIR / \"top_products.csv\", index=False)\n",
        "\n",
        "if \"Category\" in data.columns:\n",
        "    top_categories = topn([\"Category\"], \"Sales\", 10)\n",
        "    top_categories.to_csv(OUTPUT_DIR / \"top_categories.csv\", index=False)\n",
        "\n",
        "if \"Region\" in data.columns:\n",
        "    top_regions = topn([\"Region\"], \"Sales\", 10)\n",
        "    top_regions.to_csv(OUTPUT_DIR / \"top_regions.csv\", index=False)\n",
        "\n",
        "if \"Product Name\" in data.columns:\n",
        "    loss_skus = (data.groupby(\"Product Name\", as_index=False)[[\"Sales\",\"Profit\"]]\n",
        "                    .sum().query(\"Profit < 0\").sort_values(\"Profit\"))\n",
        "    loss_skus.to_csv(OUTPUT_DIR / \"loss_making_products.csv\", index=False)\n",
        "\n",
        "\n",
        "if \"Discount\" in data.columns:\n",
        "    corr = data[[\"Discount\",\"Profit Margin %\"]].dropna().corr().iloc[0,1]\n",
        "    with open(OUTPUT_DIR / \"discount_margin_correlation.txt\", \"w\") as f:\n",
        "        f.write(f\"Correlation(Discount, Profit Margin %): {corr:.4f}\")"
      ],
      "metadata": {
        "id": "3CXOGFFkRKRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Time series & Seasonality\n",
        "# -------------------------\n",
        "ts = data.set_index(DATE_COL).sort_index()\n",
        "sales_m = ts[\"Sales\"].resample(\"MS\").sum()\n",
        "\n",
        "sales_m.to_csv(OUTPUT_DIR / \"monthly_sales.csv\")\n",
        "plt.figure(figsize=(10,5))\n",
        "sales_m.plot()\n",
        "plt.title(\"Monthly Sales\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"monthly_sales.png\")\n",
        "plt.close()\n",
        "\n",
        "if HAS_SM and len(sales_m.dropna()) >= 24:\n",
        "    result = seasonal_decompose(sales_m, model=\"additive\", period=12)\n",
        "    # Trend\n",
        "    plt.figure(figsize=(10,4))\n",
        "    result.trend.plot()\n",
        "    plt.title(\"Sales Trend\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUTPUT_DIR / \"sales_trend.png\")\n",
        "    plt.close()\n",
        "    # Seasonality\n",
        "    plt.figure(figsize=(10,4))\n",
        "    result.seasonal.plot()\n",
        "    plt.title(\"Seasonality\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUTPUT_DIR / \"sales_seasonality.png\")\n",
        "    plt.close()\n",
        "\n",
        "if HAS_SM and len(sales_m.dropna()) >= 18:\n",
        "    train = sales_m.dropna()\n",
        "    try:\n",
        "        model = ARIMA(train, order=(1,1,1)).fit()\n",
        "        forecast = model.forecast(steps=3)\n",
        "        fc_df = pd.DataFrame({\"Forecast\": forecast})\n",
        "        fc_df.to_csv(OUTPUT_DIR / \"monthly_sales_forecast.csv\")\n",
        "    except Exception as e:\n",
        "        with open(OUTPUT_DIR / \"forecast_error.txt\", \"w\") as f:\n",
        "            f.write(str(e))"
      ],
      "metadata": {
        "id": "G7dSBN13RbKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Cohorts & RFM (Customer Value)\n",
        "# -------------------------\n",
        "if CUST_COL in data.columns:\n",
        "    # RFM\n",
        "    ref_date = data[DATE_COL].max() + pd.Timedelta(days=1)\n",
        "    rfm = (data\n",
        "           .groupby(CUST_COL)\n",
        "           .agg({\n",
        "               DATE_COL: lambda s: (ref_date - s.max()).days, # Recency\n",
        "               ID_COL: \"nunique\" if ID_COL in data.columns else \"count\",   # Frequency\n",
        "               \"Sales\": \"sum\"    # Monetary\n",
        "           }).rename(columns={DATE_COL:\"RecencyDays\", ID_COL:\"Frequency\", \"Sales\":\"Monetary\"}))\n",
        "    # Score each 1(low) - 5(high)\n",
        "    rfm[\"R_Score\"] = pd.qcut(rfm[\"RecencyDays\"].rank(method=\"first\"), 5, labels=[5,4,3,2,1]).astype(int)\n",
        "    rfm[\"F_Score\"] = pd.qcut(rfm[\"Frequency\"].rank(method=\"first\"), 5, labels=[1,2,3,4,5]).astype(int)\n",
        "    rfm[\"M_Score\"] = pd.qcut(rfm[\"Monetary\"].rank(method=\"first\"), 5, labels=[1,2,3,4,5]).astype(int)\n",
        "    rfm[\"RFM_Segment\"] = rfm[\"R_Score\"].astype(str)+rfm[\"F_Score\"].astype(str)+rfm[\"M_Score\"].astype(str)\n",
        "    rfm[\"RFM_Score\"] = rfm[[\"R_Score\",\"F_Score\",\"M_Score\"]].sum(axis=1)\n",
        "    rfm.to_csv(OUTPUT_DIR / \"rfm_customers.csv\")\n",
        "\n",
        "    # Cohort: first purchase month vs retention\n",
        "    d = data[[CUST_COL, DATE_COL, ID_COL]].dropna().copy()\n",
        "    d[\"OrderMonth\"] = d[DATE_COL].values.astype(\"datetime64[M]\")\n",
        "    first = d.groupby(CUST_COL)[\"OrderMonth\"].min().rename(\"Cohort\")\n",
        "    d = d.join(first, on=CUST_COL)\n",
        "    d[\"CohortIndex\"] = ((d[\"OrderMonth\"].dt.year - d[\"Cohort\"].dt.year)*12 +\n",
        "                        (d[\"OrderMonth\"].dt.month - d[\"Cohort\"].dt.month) + 1)\n",
        "    cohort = (d.groupby([\"Cohort\",\"CohortIndex\"])[CUST_COL]\n",
        "                .nunique().unstack(fill_value=0))\n",
        "    # Convert to retention %\n",
        "    cohort_pct = cohort.divide(cohort.iloc[:,0], axis=0).round(3)\n",
        "    cohort_pct.to_csv(OUTPUT_DIR / \"cohort_retention.csv\")\n"
      ],
      "metadata": {
        "id": "F-wAVUNVReLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) ABC (Pareto) Analysis by Sales & Profit\n",
        "# -------------------------\n",
        "key = \"Product Name\" if \"Product Name\" in data.columns else \"Product ID\" if \"Product ID\" in data.columns else None\n",
        "if key:\n",
        "    prod = data.groupby(key, as_index=False)[[\"Sales\",\"Profit\"]].sum().sort_values(\"Sales\", ascending=False)\n",
        "    prod[\"Sales_Cum%\"] = prod[\"Sales\"].cumsum() / prod[\"Sales\"].sum()\n",
        "    prod[\"ABC_Sales\"] = pd.cut(prod[\"Sales_Cum%\"], bins=[0,0.8,0.95,1.0], labels=[\"A\",\"B\",\"C\"], include_lowest=True)\n",
        "    prod[\"Profit_Cum%\"] = prod[\"Profit\"].cumsum() / prod[\"Profit\"].sum() if prod[\"Profit\"].sum()!=0 else np.nan\n",
        "    prod[\"ABC_Profit\"] = pd.cut(prod[\"Profit_Cum%\"], bins=[0,0.8,0.95,1.0], labels=[\"A\",\"B\",\"C\"], include_lowest=True)\n",
        "    prod.to_csv(OUTPUT_DIR / \"abc_products.csv\", index=False)"
      ],
      "metadata": {
        "id": "xOubk2kRRreQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) Visuals (saved as PNG)\n",
        "# -------------------------\n",
        "def bar_save(series, title, fname, xlabel=\"\", ylabel=\"\"):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    series.plot(kind=\"bar\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUTPUT_DIR / fname)\n",
        "    plt.close()\n",
        "\n",
        "# Sales by Month\n",
        "sales_by_month = data.groupby([\"Year\",\"Month\"], as_index=False)[\"Sales\"].sum()\n",
        "sales_by_month[\"YearMonth\"] = pd.to_datetime(sales_by_month[\"Year\"].astype(str) + \"-\" + sales_by_month[\"Month\"].astype(str) + \"-01\")\n",
        "sales_by_month = sales_by_month.set_index(\"YearMonth\")[\"Sales\"].sort_index()\n",
        "plt.figure(figsize=(10,5))\n",
        "sales_by_month.plot()\n",
        "plt.title(\"Sales by Month\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"sales_by_month.png\")\n",
        "plt.close()\n",
        "\n",
        "# Category performance\n",
        "if \"Category\" in data.columns:\n",
        "    cat = data.groupby(\"Category\")[[\"Sales\",\"Profit\"]].sum().sort_values(\"Sales\", ascending=False)\n",
        "    bar_save(cat[\"Sales\"], \"Sales by Category\", \"sales_by_category.png\", ylabel=\"Sales\")\n",
        "    bar_save(cat[\"Profit\"], \"Profit by Category\", \"profit_by_category.png\", ylabel=\"Profit\")\n",
        "\n",
        "# Region performance\n",
        "if \"Region\" in data.columns:\n",
        "    reg = data.groupby(\"Region\")[[\"Sales\",\"Profit\"]].sum().sort_values(\"Sales\", ascending=False)\n",
        "    bar_save(reg[\"Sales\"], \"Sales by Region\", \"sales_by_region.png\", ylabel=\"Sales\")\n",
        "    bar_save(reg[\"Profit\"], \"Profit by Region\", \"profit_by_region.png\", ylabel=\"Profit\")\n",
        "\n",
        "# Weekday pattern\n",
        "wk = data.groupby(\"Weekday\")[\"Sales\"].sum().reindex(\n",
        "    [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
        ")\n",
        "bar_save(wk, \"Sales by Weekday\", \"sales_by_weekday.png\", ylabel=\"Sales\")\n",
        "\n",
        "print(f\"Done. Files saved in: {OUTPUT_DIR.resolve()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX8P9LRcR7Ah",
        "outputId": "86704468-807c-4616-cce0-c5547c43f787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Files saved in: /content/outputs\n"
          ]
        }
      ]
    }
  ]
}